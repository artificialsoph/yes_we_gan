{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:35.864032Z",
     "start_time": "2018-06-25T02:36:34.314108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:36.598280Z",
     "start_time": "2018-06-25T02:36:36.595167Z"
    }
   },
   "outputs": [],
   "source": [
    "# SOPH: review these params and update accordingly\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "num_classes = 10\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:38.581364Z",
     "start_time": "2018-06-25T02:36:36.989843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 158,112\n",
      "Trainable params: 157,728\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "disk summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 256)               158112    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 158,369\n",
      "Trainable params: 157,985\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "q summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 256)               158112    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 166,666\n",
      "Trainable params: 166,282\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build discriminator\n",
    "\n",
    "DROP = .25\n",
    "\n",
    "img = keras.Input(shape=img_shape)\n",
    "\n",
    "conv = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=img_shape),\n",
    "    \n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(32, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(32, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(64, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "])\n",
    "conv.summary()\n",
    "img_embedding = conv(img)\n",
    "\n",
    "# Discriminator\n",
    "validity = keras.layers.Dense(1, activation='sigmoid')(img_embedding)\n",
    "\n",
    "# Recognition\n",
    "q_net = keras.layers.Dense(32, activation='elu')(img_embedding)\n",
    "\n",
    "label = keras.layers.Dense(num_classes, activation='softmax')(q_net)\n",
    "\n",
    "disk = keras.Model(img, validity)\n",
    "\n",
    "print(\"disk summary:\")\n",
    "disk.summary()\n",
    "\n",
    "q = keras.Model(img, label)\n",
    "\n",
    "print(\"q summary\")\n",
    "q.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:39.197931Z",
     "start_time": "2018-06-25T02:36:38.603451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               37376     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 1)         801       \n",
      "=================================================================\n",
      "Total params: 94,177\n",
      "Trainable params: 93,921\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DROP = .25\n",
    "\n",
    "generator = keras.Sequential([\n",
    "    keras.layers.Dense(4*4*32, activation=\"elu\", input_dim=latent_dim),\n",
    "    keras.layers.Reshape((4, 4, 32)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(32, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(32, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(32, 3, padding=\"valid\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(32, 3, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(channels, 5, padding=\"same\", activation=\"tanh\"),\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:39.694517Z",
     "start_time": "2018-06-25T02:36:39.217146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 37,952\n",
      "Trainable params: 37,632\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DROP = .25\n",
    "\n",
    "conv = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=img_shape),\n",
    "    \n",
    "    keras.layers.Conv2D(32, 3, strides=2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(32, 3, strides=2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(32, 3, strides=2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(64, 3, strides=2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "#     keras.layers.Dropout(DROP),\n",
    "    \n",
    "    \n",
    "    keras.layers.GlobalAvgPool2D(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "])\n",
    "conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:39.716089Z",
     "start_time": "2018-06-25T02:36:39.713116Z"
    }
   },
   "outputs": [],
   "source": [
    "def mutual_info_loss(c, c_given_x):\n",
    "    \"\"\"The mutual information metric we aim to minimize\"\"\"\n",
    "    eps = 1e-8\n",
    "    conditional_entropy = K.mean(- K.sum(K.log(c_given_x + eps) * c, axis=1))\n",
    "    entropy = K.mean(- K.sum(K.log(c + eps) * c, axis=1))\n",
    "\n",
    "    return conditional_entropy + entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:39.811732Z",
     "start_time": "2018-06-25T02:36:39.734000Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "losses = ['binary_crossentropy', mutual_info_loss]\n",
    "\n",
    "# Build and the discriminator and recognition network\n",
    "\n",
    "disk.compile(loss=['binary_crossentropy'],\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Build and compile the recognition network Q\n",
    "q.compile(loss=[mutual_info_loss],\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:40.799808Z",
     "start_time": "2018-06-25T02:36:39.829645Z"
    }
   },
   "outputs": [],
   "source": [
    "# The generator takes noise and the target label as input\n",
    "# and generates the corresponding digit of that label\n",
    "gen_input = keras.Input(shape=(latent_dim,))\n",
    "img = generator(gen_input)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "disk.trainable = False\n",
    "\n",
    "# The discriminator takes generated image as input and determines validity\n",
    "valid = disk(img)\n",
    "# The recognition network produces the label\n",
    "target_label = q(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "combined = keras.Model(gen_input, [valid, target_label])\n",
    "combined.compile(loss=losses, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T02:36:40.827898Z",
     "start_time": "2018-06-25T02:36:40.820656Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_generator_input(batch_size):\n",
    "    # Generator inputs\n",
    "    sampled_noise = np.random.normal(0, 1, (batch_size, 62))\n",
    "\n",
    "\n",
    "    # SOPH: this code generates random combinations of your labels so that it can generate randomized images\n",
    "    # the following code should be removed and replaced with something that generates random values for your 40\n",
    "    # labels\n",
    "    sampled_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "    sampled_labels = keras.utils.to_categorical(sampled_labels, num_classes=num_classes)\n",
    "\n",
    "    return sampled_noise, sampled_labels\n",
    "\n",
    "\n",
    "def sample_images(epoch):\n",
    "    # SOPH: this'll be hard to adjust so consider just removing it or greatly simplifying it to start out.\n",
    "    # this generates those image matrices.\n",
    "    r, c = 10, 10\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    for i in range(c):\n",
    "        sampled_noise, _ = sample_generator_input(c)\n",
    "        label = keras.utils.to_categorical(np.full(fill_value=i, shape=(r,1)), num_classes=num_classes)\n",
    "        gen_input = np.concatenate((sampled_noise, label), axis=1)\n",
    "        gen_imgs = generator.predict(gen_input)\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        for j in range(r):\n",
    "            axs[j,i].imshow(gen_imgs[j,:,:,0], cmap='gray')\n",
    "            axs[j,i].axis('off')\n",
    "    fig.savefig(\"images/%05d.png\" % epoch)\n",
    "    plt.close()\n",
    "\n",
    "def save_model():\n",
    "\n",
    "    def save(model, model_name):\n",
    "        model_path = \"saved_model/%s.json\" % model_name\n",
    "        weights_path = \"saved_model/%s_weights.hdf5\" % model_name\n",
    "        options = {\"file_arch\": model_path,\n",
    "                    \"file_weight\": weights_path}\n",
    "        json_string = model.to_json()\n",
    "        open(options['file_arch'], 'w').write(json_string)\n",
    "        model.save_weights(options['file_weight'])\n",
    "\n",
    "    save(generator, \"generator\")\n",
    "    save(discriminator, \"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-25T02:36:40.511Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.6/site-packages/keras/engine/training.py:975: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.90, acc.: 23.44%] [Q loss: 0.73] [G loss: 3.37]\n",
      "50 [D loss: 0.43, acc.: 37.11%] [Q loss: 1.19] [G loss: 2.50]\n",
      "100 [D loss: 0.43, acc.: 39.45%] [Q loss: 1.09] [G loss: 2.46]\n",
      "150 [D loss: 0.39, acc.: 42.58%] [Q loss: 1.14] [G loss: 2.33]\n",
      "200 [D loss: 0.37, acc.: 44.53%] [Q loss: 1.04] [G loss: 2.36]\n",
      "250 [D loss: 0.51, acc.: 30.08%] [Q loss: 1.02] [G loss: 2.50]\n",
      "300 [D loss: 0.35, acc.: 45.31%] [Q loss: 2.12] [G loss: 2.31]\n",
      "350 [D loss: 0.34, acc.: 48.83%] [Q loss: 2.08] [G loss: 2.38]\n",
      "400 [D loss: 0.35, acc.: 45.70%] [Q loss: 1.74] [G loss: 2.37]\n",
      "450 [D loss: 0.34, acc.: 44.53%] [Q loss: 1.77] [G loss: 2.21]\n",
      "500 [D loss: 0.34, acc.: 46.09%] [Q loss: 1.58] [G loss: 1.84]\n",
      "550 [D loss: 0.33, acc.: 46.09%] [Q loss: 1.65] [G loss: 1.35]\n",
      "600 [D loss: 0.34, acc.: 47.66%] [Q loss: 1.57] [G loss: 0.79]\n",
      "650 [D loss: 0.32, acc.: 47.66%] [Q loss: 1.51] [G loss: 0.43]\n",
      "700 [D loss: 0.32, acc.: 47.66%] [Q loss: 1.56] [G loss: 0.31]\n",
      "750 [D loss: 0.30, acc.: 48.83%] [Q loss: 1.58] [G loss: 0.32]\n",
      "800 [D loss: 0.33, acc.: 46.48%] [Q loss: 1.62] [G loss: 0.26]\n",
      "850 [D loss: 0.33, acc.: 46.48%] [Q loss: 1.71] [G loss: 0.31]\n",
      "900 [D loss: 0.31, acc.: 47.66%] [Q loss: 1.78] [G loss: 0.31]\n",
      "950 [D loss: 0.31, acc.: 47.66%] [Q loss: 1.70] [G loss: 0.31]\n",
      "1000 [D loss: 0.32, acc.: 48.44%] [Q loss: 1.66] [G loss: 0.24]\n",
      "1050 [D loss: 0.32, acc.: 45.31%] [Q loss: 1.75] [G loss: 0.26]\n",
      "1100 [D loss: 0.30, acc.: 47.66%] [Q loss: 1.71] [G loss: 0.32]\n",
      "1150 [D loss: 0.30, acc.: 48.05%] [Q loss: 1.82] [G loss: 0.28]\n",
      "1200 [D loss: 0.31, acc.: 47.66%] [Q loss: 1.78] [G loss: 0.22]\n",
      "1250 [D loss: 0.29, acc.: 48.44%] [Q loss: 1.80] [G loss: 0.26]\n",
      "1300 [D loss: 0.29, acc.: 49.22%] [Q loss: 1.76] [G loss: 0.28]\n",
      "1350 [D loss: 0.29, acc.: 49.22%] [Q loss: 1.82] [G loss: 0.32]\n",
      "1400 [D loss: 0.32, acc.: 47.66%] [Q loss: 1.62] [G loss: 0.63]\n",
      "1450 [D loss: 0.25, acc.: 50.00%] [Q loss: 1.54] [G loss: 0.58]\n",
      "1500 [D loss: 0.26, acc.: 49.61%] [Q loss: 1.82] [G loss: 0.67]\n",
      "1550 [D loss: 0.26, acc.: 49.22%] [Q loss: 2.02] [G loss: 0.53]\n",
      "1600 [D loss: 0.26, acc.: 49.61%] [Q loss: 2.06] [G loss: 0.66]\n",
      "1650 [D loss: 0.29, acc.: 49.61%] [Q loss: 1.57] [G loss: 0.49]\n",
      "1700 [D loss: 0.30, acc.: 48.05%] [Q loss: 2.12] [G loss: 0.79]\n",
      "1750 [D loss: 0.26, acc.: 49.22%] [Q loss: 1.96] [G loss: 0.36]\n",
      "1800 [D loss: 0.25, acc.: 50.00%] [Q loss: 2.01] [G loss: 0.41]\n",
      "1850 [D loss: 0.26, acc.: 49.61%] [Q loss: 2.01] [G loss: 0.34]\n",
      "1900 [D loss: 0.26, acc.: 50.00%] [Q loss: 2.04] [G loss: 0.22]\n",
      "1950 [D loss: 0.26, acc.: 50.00%] [Q loss: 2.25] [G loss: 0.17]\n",
      "2000 [D loss: 0.27, acc.: 49.22%] [Q loss: 2.17] [G loss: 0.21]\n",
      "2050 [D loss: 0.27, acc.: 49.22%] [Q loss: 2.07] [G loss: 0.23]\n",
      "2100 [D loss: 0.25, acc.: 49.61%] [Q loss: 2.26] [G loss: 0.18]\n",
      "2150 [D loss: 0.28, acc.: 48.83%] [Q loss: 2.30] [G loss: 0.13]\n",
      "2200 [D loss: 0.26, acc.: 49.61%] [Q loss: 2.22] [G loss: 0.26]\n",
      "2250 [D loss: 0.25, acc.: 49.61%] [Q loss: 2.22] [G loss: 0.18]\n",
      "2300 [D loss: 0.26, acc.: 49.22%] [Q loss: 2.27] [G loss: 0.13]\n",
      "2350 [D loss: 0.26, acc.: 49.22%] [Q loss: 2.24] [G loss: 0.16]\n",
      "2400 [D loss: 0.25, acc.: 49.22%] [Q loss: 2.29] [G loss: 0.14]\n",
      "2450 [D loss: 0.26, acc.: 48.44%] [Q loss: 2.33] [G loss: 0.16]\n",
      "2500 [D loss: 0.26, acc.: 48.44%] [Q loss: 2.41] [G loss: 0.28]\n",
      "2550 [D loss: 0.23, acc.: 50.00%] [Q loss: 2.49] [G loss: 0.14]\n",
      "2600 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.49] [G loss: 0.12]\n",
      "2650 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.37] [G loss: 0.21]\n",
      "2700 [D loss: 0.25, acc.: 50.00%] [Q loss: 2.28] [G loss: 0.15]\n",
      "2750 [D loss: 0.25, acc.: 50.00%] [Q loss: 2.32] [G loss: 0.09]\n",
      "2800 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.49] [G loss: 0.16]\n",
      "2850 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.62] [G loss: 0.16]\n",
      "2900 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.43] [G loss: 0.12]\n",
      "2950 [D loss: 0.25, acc.: 49.61%] [Q loss: 2.32] [G loss: 0.13]\n",
      "3000 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.55] [G loss: 0.15]\n",
      "3050 [D loss: 0.23, acc.: 50.00%] [Q loss: 2.38] [G loss: 0.17]\n",
      "3100 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.54] [G loss: 0.21]\n",
      "3150 [D loss: 0.25, acc.: 49.61%] [Q loss: 2.63] [G loss: 0.24]\n",
      "3200 [D loss: 0.24, acc.: 50.00%] [Q loss: 2.45] [G loss: 0.19]\n",
      "3250 [D loss: 0.25, acc.: 49.22%] [Q loss: 2.58] [G loss: 0.26]\n",
      "3300 [D loss: 0.23, acc.: 49.61%] [Q loss: 2.60] [G loss: 0.25]\n",
      "3350 [D loss: 0.23, acc.: 50.00%] [Q loss: 2.60] [G loss: 0.36]\n",
      "3400 [D loss: 0.23, acc.: 49.61%] [Q loss: 2.56] [G loss: 0.20]\n",
      "3450 [D loss: 0.23, acc.: 49.61%] [Q loss: 2.62] [G loss: 0.28]\n",
      "3500 [D loss: 0.24, acc.: 49.22%] [Q loss: 2.44] [G loss: 0.32]\n",
      "3550 [D loss: 0.28, acc.: 48.83%] [Q loss: 2.28] [G loss: 0.81]\n",
      "3600 [D loss: 0.22, acc.: 50.00%] [Q loss: 2.40] [G loss: 0.83]\n",
      "3650 [D loss: 0.22, acc.: 50.00%] [Q loss: 2.64] [G loss: 0.49]\n",
      "3700 [D loss: 0.22, acc.: 50.00%] [Q loss: 2.03] [G loss: 0.49]\n",
      "3750 [D loss: 0.21, acc.: 50.00%] [Q loss: 3.50] [G loss: 0.34]\n",
      "3800 [D loss: 0.23, acc.: 49.61%] [Q loss: 3.00] [G loss: 0.23]\n",
      "3850 [D loss: 0.22, acc.: 50.00%] [Q loss: 2.92] [G loss: 0.30]\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "sample_interval=50\n",
    "epochs = 10000\n",
    "smooth = .1\n",
    "\n",
    "# SOPH: replace the following code block with code that loads celebA. \n",
    "# x_train should be [n_examples x pixels x pixels]\n",
    "# y_train should be [n_examples x n_labels]\n",
    "# Load the dataset\n",
    "(X_train, y_train), (_, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "# SOPH: this is the end of the loading code. You may have to replace/remove any of these lines\n",
    "\n",
    "# Adversarial ground truths\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake = np.zeros((batch_size, 1))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    # Select a random half batch of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    # Sample noise and categorical labels\n",
    "    sampled_noise, sampled_labels = sample_generator_input(batch_size)\n",
    "    gen_input = np.concatenate((sampled_noise, sampled_labels), axis=1)\n",
    "\n",
    "    # Generate a half batch of new images\n",
    "    gen_imgs = generator.predict(gen_input)\n",
    "\n",
    "    # Train on real and generated data\n",
    "    d_loss_real = disk.train_on_batch(imgs, valid*(1-smooth))\n",
    "    d_loss_fake = disk.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "    # Avg. loss\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Generator and Q-network\n",
    "    # ---------------------\n",
    "\n",
    "    g_loss = combined.train_on_batch(gen_input, [valid, sampled_labels])\n",
    "\n",
    "    # Plot the progress\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % sample_interval == 0:\n",
    "        print (\"%d [D loss: %.2f, acc.: %.2f%%] [Q loss: %.2f] [G loss: %.2f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[1], g_loss[2]))\n",
    "        sample_images(epoch//sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-25T02:36:41.948Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "sample_interval=50\n",
    "epochs = 1000\n",
    "smooth = .1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    # Select a random half batch of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    imgs = X_train[idx]\n",
    "\n",
    "    # Sample noise and categorical labels\n",
    "    sampled_noise, sampled_labels = sample_generator_input(batch_size)\n",
    "    gen_input = np.concatenate((sampled_noise, sampled_labels), axis=1)\n",
    "\n",
    "    # Generate a half batch of new images\n",
    "    gen_imgs = generator.predict(gen_input)\n",
    "\n",
    "    # Train on real and generated data\n",
    "    d_loss_real = disk.train_on_batch(imgs, valid)\n",
    "    d_loss_fake = disk.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "    # Avg. loss\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "    # Plot the progress\n",
    "\n",
    "    # If at save interval => save generated image samples\n",
    "    if epoch % sample_interval == 0:\n",
    "        \n",
    "         # ---------------------\n",
    "        #  Train Generator and Q-network\n",
    "        # ---------------------\n",
    "\n",
    "        g_loss = combined.train_on_batch(gen_input, [valid, sampled_labels])\n",
    "        \n",
    "        print (\"%d [D loss: %.2f, acc.: %.2f%%] [Q loss: %.2f] [G loss: %.2f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[1], g_loss[2]))\n",
    "        sample_images(epoch//sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
