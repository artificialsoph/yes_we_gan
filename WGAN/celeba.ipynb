{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:02:05.938991Z",
     "start_time": "2018-07-10T15:02:04.338844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# references\n",
    "# - https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# - https://github.com/eriklindernoren/Keras-GAN/blob/master/wgan_gp/wgan_gp.py\n",
    "# - https://github.com/LynnHo/WGAN-GP-DRAGAN-Celeba-Pytorch/blob/master/models_64x64.py\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import keras\n",
    "import keras_contrib\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:02:05.943543Z",
     "start_time": "2018-07-10T15:02:05.940848Z"
    }
   },
   "outputs": [],
   "source": [
    "# 218, 178"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:02:05.950887Z",
     "start_time": "2018-07-10T15:02:05.945416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.25688073394495"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "178/(218/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:02:05.979386Z",
     "start_time": "2018-07-10T15:02:05.952869Z"
    }
   },
   "outputs": [],
   "source": [
    "num_images = 50000\n",
    "img_shape = [64, 52, 3]\n",
    "\n",
    "img_rows = img_shape[0]\n",
    "img_cols = img_shape[1]\n",
    "channels = img_shape[2]\n",
    "latent_dim = 100\n",
    "\n",
    "# Following parameter and optimizer set as recommended in paper\n",
    "n_critic = 5\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:02:06.225821Z",
     "start_time": "2018-07-10T15:02:05.981309Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import lycon\n",
    "from skimage import transform\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:02:06.231954Z",
     "start_time": "2018-07-10T15:02:06.227637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:03:55.614139Z",
     "start_time": "2018-07-10T15:02:06.234461Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [01:48<00:00, 459.64it/s]\n"
     ]
    }
   ],
   "source": [
    "im_files = glob.glob(\"/home/ubuntu/downloads/img_align_celeba/*.jpg\")\n",
    "\n",
    "X_train = np.zeros([num_images] + img_shape)\n",
    "\n",
    "for i in trange(num_images):\n",
    "\n",
    "    X_train[i, ...] = lycon.resize(\n",
    "        lycon.load(im_files[i]),\n",
    "        width=img_shape[1],\n",
    "        height=img_shape[0],\n",
    "        interpolation=lycon.Interpolation.LINEAR)\n",
    "\n",
    "    imageio.imread(im_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:03:56.303510Z",
     "start_time": "2018-07-10T15:03:55.616065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 255.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:03:58.216422Z",
     "start_time": "2018-07-10T15:03:56.305368Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train*(2/255) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:03:58.911461Z",
     "start_time": "2018-07-10T15:03:58.218406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:00.392216Z",
     "start_time": "2018-07-10T15:03:58.913354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 16, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 26, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 64, 52, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 52, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 52, 3)         4803      \n",
      "=================================================================\n",
      "Total params: 1,339,971\n",
      "Trainable params: 1,339,203\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the generator and critic\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128 * 4 * 4, activation=\"relu\", input_dim=latent_dim),\n",
    "    keras.layers.Reshape((4, 4, 128)),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "    \n",
    "    \n",
    "    keras.layers.Conv2DTranspose(128, kernel_size=5, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras.layers.Cropping2D(((0, 0), (1, 2))),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "#     keras.layers.Cropping2D(((0, 0), (1, 1))),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\"),\n",
    "    keras.layers.BatchNormalization(momentum=0.8),\n",
    "#     keras.layers.Cropping2D(((0, 0), (1, 2))),\n",
    "    \n",
    "    keras.layers.Conv2D(channels, kernel_size=5, padding=\"same\", activation=\"tanh\"),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "noise = keras.Input(shape=(latent_dim,))\n",
    "img = model(noise)\n",
    "\n",
    "generator = keras.Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:00.734148Z",
     "start_time": "2018-07-10T15:04:00.394271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 32, 26, 16)        2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 13, 32)        4640      \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 16, 13, 32)        2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "instance_normalization_3 (In (None, 8, 7, 64)          2         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 99,495\n",
      "Trainable params: 99,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\", activation=\"elu\"),\n",
    "#     keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras_contrib.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    keras.layers.Conv2D(32, kernel_size=3, strides=2, padding=\"same\"),\n",
    "#     keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras_contrib.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    keras.layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\"),\n",
    "#     keras.layers.BatchNormalization(momentum=0.8),\n",
    "    keras_contrib.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=.2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "#     keras.layers.BatchNormalization(momentum=0.8),\n",
    "#     keras_contrib.layers.InstanceNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=.2),\n",
    "    \n",
    "#     keras.layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
    "#     keras.layers.BatchNormalization(momentum=0.8),\n",
    "#     keras.layers.LeakyReLU(alpha=.2),\n",
    "#     keras.layers.Dropout(0.25),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "img = keras.Input(shape=img_shape)\n",
    "validity = model(img)\n",
    "\n",
    "critic =  keras.Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:00.743250Z",
     "start_time": "2018-07-10T15:04:00.736702Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomWeightedAverage(keras.layers.merge._Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((32, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:00.753095Z",
     "start_time": "2018-07-10T15:04:00.746945Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    \"\"\"\n",
    "    Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "    \"\"\"\n",
    "    gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "    # compute the euclidean norm by squaring ...\n",
    "    gradients_sqr = K.square(gradients)\n",
    "    #   ... summing over the rows ...\n",
    "    gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                              axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    #   ... and sqrt\n",
    "    gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "    # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "    gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "    # return the mean as loss over all the batch samples\n",
    "    return K.mean(gradient_penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:00.758817Z",
     "start_time": "2018-07-10T15:04:00.756159Z"
    }
   },
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:01.596588Z",
     "start_time": "2018-07-10T15:04:00.760754Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#       for the Critic\n",
    "#-------------------------------\n",
    "\n",
    "# Freeze generator's layers while training critic\n",
    "generator.trainable = False\n",
    "\n",
    "# Image input (real sample)\n",
    "real_img = keras.Input(shape=img_shape)\n",
    "\n",
    "# Noise input\n",
    "z_disc = keras.Input(shape=(latent_dim,))\n",
    "# Generate image based of noise (fake sample)\n",
    "fake_img = generator(z_disc)\n",
    "\n",
    "# Discriminator determines validity of the real and fake images\n",
    "fake = critic(fake_img)\n",
    "valid = critic(real_img)\n",
    "\n",
    "# Construct weighted average between real and fake images\n",
    "interpolated_img = RandomWeightedAverage()([real_img, fake_img])\n",
    "# Determine validity of weighted sample\n",
    "validity_interpolated = critic(interpolated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:02.212866Z",
     "start_time": "2018-07-10T15:04:01.598643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use Python partial to provide loss function with additional\n",
    "# 'averaged_samples' argument\n",
    "partial_gp_loss = partial(gradient_penalty_loss,\n",
    "                  averaged_samples=interpolated_img)\n",
    "partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "critic_model = keras.Model(inputs=[real_img, z_disc],\n",
    "                    outputs=[valid, fake, validity_interpolated])\n",
    "critic_model.compile(loss=[wasserstein_loss,\n",
    "                                      wasserstein_loss,\n",
    "                                      partial_gp_loss],\n",
    "                                optimizer=optimizer,\n",
    "                                loss_weights=[1, 1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:02.826475Z",
     "start_time": "2018-07-10T15:04:02.214909Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#         for Generator\n",
    "#-------------------------------\n",
    "\n",
    "# For the generator we freeze the critic's layers\n",
    "critic.trainable = False\n",
    "generator.trainable = True\n",
    "\n",
    "# Sampled noise for input to generator\n",
    "z_gen = keras.Input(shape=(latent_dim,))\n",
    "# Generate images based of noise\n",
    "img = generator(z_gen)\n",
    "# Discriminator determines validity\n",
    "valid = critic(img)\n",
    "# Defines generator model\n",
    "generator_model = keras.Model(z_gen, valid)\n",
    "generator_model.compile(loss=wasserstein_loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T15:04:02.836939Z",
     "start_time": "2018-07-10T15:04:02.828516Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "def train(epochs, batch_size, sample_interval=50):\n",
    "\n",
    "    shutil.rmtree(\"celeba_images\", ignore_errors=True)\n",
    "    os.makedirs(\"celeba_images\", exist_ok=True)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = -np.ones((batch_size, 1))\n",
    "    fake =  np.ones((batch_size, 1))\n",
    "    dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for _ in range(n_critic):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "            # Sample generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "            # Train the critic\n",
    "            d_loss = critic_model.train_on_batch([imgs, noise],\n",
    "                                                            [valid, fake, dummy])\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        g_loss = generator_model.train_on_batch(noise, valid)\n",
    "        \n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "            sample_images(epoch)\n",
    "\n",
    "def sample_images(epoch):\n",
    "    # make a video with \n",
    "    # >ffmpeg -y -framerate 4 -pattern_type glob -i 'im_*.png' -pix_fmt yuv420p -vf scale=500:-1 output.mp4\n",
    "    \n",
    "    \n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + .5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c, sharex=True, sharey=True, frameon=False, figsize=(5,5))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt,...], aspect=\"auto\")\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.tight_layout(h_pad=0, w_pad=0)\n",
    "    plt.suptitle(f'epoch: {epoch}', backgroundcolor=\"white\")\n",
    "    fig.savefig(f\"celeba_images/im_{epoch:05d}.png\", dpi=200)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-10T15:02:04.364Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.6/site-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.071010] [G loss: 0.399737]\n",
      "100 [D loss: -15.906043] [G loss: 11.872585]\n",
      "200 [D loss: -10.462564] [G loss: 12.331842]\n",
      "300 [D loss: -6.009324] [G loss: 6.556452]\n",
      "400 [D loss: -2.258909] [G loss: -5.384147]\n",
      "500 [D loss: -0.662623] [G loss: -8.165950]\n",
      "600 [D loss: -1.386973] [G loss: -5.359030]\n",
      "700 [D loss: -0.288987] [G loss: -0.037723]\n",
      "800 [D loss: -2.307323] [G loss: 5.657558]\n",
      "900 [D loss: -2.037921] [G loss: -8.884901]\n",
      "1000 [D loss: -2.822394] [G loss: -8.537423]\n",
      "1100 [D loss: -0.489803] [G loss: -15.163243]\n",
      "1200 [D loss: -1.426459] [G loss: -18.684834]\n",
      "1300 [D loss: -1.630782] [G loss: -21.376253]\n",
      "1400 [D loss: -2.592243] [G loss: -22.582027]\n",
      "1500 [D loss: -1.676471] [G loss: -29.899513]\n",
      "1600 [D loss: -2.051211] [G loss: -25.263687]\n",
      "1700 [D loss: -2.363373] [G loss: -26.964220]\n",
      "1800 [D loss: -2.178939] [G loss: -26.493341]\n",
      "1900 [D loss: -2.008708] [G loss: -28.711365]\n",
      "2000 [D loss: -2.075954] [G loss: -33.315414]\n",
      "2100 [D loss: -1.926997] [G loss: -29.601543]\n",
      "2200 [D loss: -1.586629] [G loss: -28.407337]\n",
      "2300 [D loss: -0.841206] [G loss: -32.208431]\n",
      "2400 [D loss: -1.292185] [G loss: -28.695015]\n",
      "2500 [D loss: -1.726810] [G loss: -30.713696]\n",
      "2600 [D loss: -0.939278] [G loss: -31.481369]\n",
      "2700 [D loss: -1.856715] [G loss: -31.763157]\n",
      "2800 [D loss: -1.577579] [G loss: -31.269308]\n",
      "2900 [D loss: -0.594687] [G loss: -32.438416]\n",
      "3000 [D loss: -1.554700] [G loss: -29.936602]\n",
      "3100 [D loss: -1.476091] [G loss: -32.485115]\n",
      "3200 [D loss: -1.506538] [G loss: -29.828880]\n",
      "3300 [D loss: -0.791145] [G loss: -30.799221]\n",
      "3400 [D loss: -1.921216] [G loss: -31.829174]\n",
      "3500 [D loss: -3.179074] [G loss: -35.888992]\n",
      "3600 [D loss: -2.751488] [G loss: -44.428448]\n",
      "3700 [D loss: -1.311270] [G loss: -44.666588]\n",
      "4100 [D loss: -3.891623] [G loss: -60.848732]\n",
      "4200 [D loss: -1.872885] [G loss: -58.362778]\n",
      "4300 [D loss: -5.072848] [G loss: -62.922394]\n",
      "4400 [D loss: -0.054262] [G loss: -62.483620]\n",
      "4500 [D loss: -2.737221] [G loss: -59.863365]\n",
      "4600 [D loss: 1.017598] [G loss: -60.610279]\n",
      "4700 [D loss: 0.402522] [G loss: -64.374634]\n",
      "4800 [D loss: -2.738353] [G loss: -69.581955]\n",
      "4900 [D loss: -4.782518] [G loss: -67.954643]\n",
      "5000 [D loss: -1.865045] [G loss: -73.445923]\n",
      "5100 [D loss: -1.610214] [G loss: -75.180252]\n",
      "5200 [D loss: -1.085436] [G loss: -62.500683]\n",
      "5300 [D loss: 0.834432] [G loss: -72.796555]\n",
      "5400 [D loss: -1.835492] [G loss: -78.225571]\n",
      "5500 [D loss: -0.478379] [G loss: -70.491074]\n",
      "5600 [D loss: -3.322613] [G loss: -83.396339]\n",
      "5700 [D loss: -2.934534] [G loss: -83.047195]\n",
      "5800 [D loss: -0.794553] [G loss: -84.657639]\n",
      "5900 [D loss: -0.838389] [G loss: -78.559235]\n",
      "6000 [D loss: -4.358235] [G loss: -83.491890]\n",
      "6100 [D loss: -4.561427] [G loss: -73.599167]\n",
      "6200 [D loss: -2.527091] [G loss: -77.459427]\n",
      "6300 [D loss: -2.989455] [G loss: -81.519585]\n",
      "6400 [D loss: -2.204354] [G loss: -76.034866]\n",
      "6500 [D loss: -1.524332] [G loss: -71.731102]\n",
      "6600 [D loss: -2.649975] [G loss: -70.177338]\n",
      "6700 [D loss: -1.523645] [G loss: -69.639931]\n",
      "6800 [D loss: -1.899133] [G loss: -62.360558]\n",
      "6900 [D loss: -0.558381] [G loss: -60.499649]\n",
      "7000 [D loss: -1.302895] [G loss: -59.122276]\n",
      "7100 [D loss: -2.201799] [G loss: -53.089615]\n",
      "7200 [D loss: -1.438138] [G loss: -51.231213]\n",
      "7300 [D loss: -1.521952] [G loss: -45.954632]\n",
      "7400 [D loss: -2.054419] [G loss: -49.034828]\n",
      "7500 [D loss: -0.559088] [G loss: -45.989613]\n",
      "7600 [D loss: 0.950437] [G loss: -45.742088]\n",
      "7700 [D loss: -1.770829] [G loss: -43.666950]\n",
      "7800 [D loss: -2.057582] [G loss: -41.303940]\n",
      "7900 [D loss: -1.066809] [G loss: -40.011627]\n",
      "8000 [D loss: -2.516970] [G loss: -37.108368]\n",
      "8100 [D loss: -0.760066] [G loss: -38.906212]\n",
      "8200 [D loss: -1.872910] [G loss: -37.769989]\n",
      "8300 [D loss: -1.343249] [G loss: -34.037346]\n",
      "8400 [D loss: 0.450721] [G loss: -35.905754]\n",
      "8500 [D loss: -1.042857] [G loss: -33.673168]\n",
      "8600 [D loss: -1.944474] [G loss: -33.693130]\n",
      "8700 [D loss: -1.611691] [G loss: -43.350693]\n",
      "8800 [D loss: -1.987843] [G loss: -42.633801]\n",
      "8900 [D loss: -2.097141] [G loss: -37.067284]\n",
      "9000 [D loss: 0.069262] [G loss: -40.349594]\n",
      "9100 [D loss: 0.129339] [G loss: -42.766945]\n",
      "9200 [D loss: -1.581622] [G loss: -42.921349]\n",
      "9300 [D loss: -1.835588] [G loss: -40.276157]\n",
      "9400 [D loss: -2.214010] [G loss: -37.714920]\n",
      "9500 [D loss: -2.721035] [G loss: -40.586445]\n",
      "9600 [D loss: -0.605835] [G loss: -31.122581]\n",
      "9700 [D loss: 0.161755] [G loss: -39.930046]\n",
      "9800 [D loss: -1.494898] [G loss: -34.786827]\n",
      "9900 [D loss: -2.131842] [G loss: -34.148140]\n",
      "10000 [D loss: 0.381112] [G loss: -34.239056]\n",
      "10100 [D loss: -1.727273] [G loss: -36.300392]\n",
      "10200 [D loss: -1.829667] [G loss: -39.518257]\n",
      "10300 [D loss: -1.613998] [G loss: -33.046181]\n",
      "10400 [D loss: -0.167815] [G loss: -35.840126]\n",
      "10500 [D loss: -1.537336] [G loss: -28.626217]\n",
      "10600 [D loss: -0.558253] [G loss: -33.952484]\n",
      "10700 [D loss: 0.963840] [G loss: -35.287315]\n",
      "10800 [D loss: -0.486474] [G loss: -32.422241]\n",
      "10900 [D loss: 0.251926] [G loss: -32.913158]\n",
      "11000 [D loss: -0.213946] [G loss: -32.894875]\n",
      "11100 [D loss: -0.511887] [G loss: -31.188257]\n",
      "11200 [D loss: -0.254247] [G loss: -34.838737]\n",
      "11300 [D loss: 0.355604] [G loss: -32.967823]\n",
      "11400 [D loss: -1.269573] [G loss: -34.709938]\n",
      "11500 [D loss: -1.193142] [G loss: -28.114985]\n",
      "11600 [D loss: -1.849634] [G loss: -29.476196]\n",
      "11700 [D loss: -0.612927] [G loss: -28.156897]\n",
      "11800 [D loss: -2.196352] [G loss: -27.070114]\n",
      "11900 [D loss: 0.394075] [G loss: -24.906540]\n",
      "12000 [D loss: -0.273143] [G loss: -23.841572]\n",
      "12100 [D loss: 0.031609] [G loss: -27.477058]\n",
      "12200 [D loss: -4.145672] [G loss: -23.447510]\n",
      "12300 [D loss: 0.015761] [G loss: -21.872826]\n",
      "12400 [D loss: -0.813466] [G loss: -21.391361]\n",
      "12500 [D loss: -1.716020] [G loss: -24.881159]\n",
      "12600 [D loss: -1.178981] [G loss: -23.282761]\n",
      "12700 [D loss: -0.954888] [G loss: -22.610611]\n",
      "12800 [D loss: -0.607631] [G loss: -30.149960]\n",
      "12900 [D loss: -0.416493] [G loss: -28.573721]\n",
      "13000 [D loss: -0.596642] [G loss: -22.267632]\n",
      "13100 [D loss: -0.283678] [G loss: -23.212633]\n",
      "13200 [D loss: -1.184309] [G loss: -21.997772]\n",
      "13300 [D loss: -0.178923] [G loss: -22.482899]\n",
      "13400 [D loss: 1.127339] [G loss: -18.708927]\n",
      "13500 [D loss: -0.313879] [G loss: -20.104420]\n",
      "13600 [D loss: -0.946705] [G loss: -23.644957]\n",
      "13700 [D loss: -1.185336] [G loss: -19.237556]\n",
      "13800 [D loss: -1.615003] [G loss: -21.874165]\n",
      "13900 [D loss: -1.459490] [G loss: -22.818756]\n",
      "14000 [D loss: 0.231633] [G loss: -19.503212]\n",
      "14100 [D loss: -0.204353] [G loss: -20.640476]\n",
      "14200 [D loss: 0.523635] [G loss: -17.846045]\n",
      "14300 [D loss: -0.194497] [G loss: -22.136679]\n",
      "14400 [D loss: -0.296190] [G loss: -21.942926]\n",
      "14500 [D loss: -0.735517] [G loss: -19.383110]\n",
      "14600 [D loss: -0.885341] [G loss: -14.429964]\n",
      "14700 [D loss: -0.665711] [G loss: -19.922287]\n",
      "14800 [D loss: -0.264131] [G loss: -21.200348]\n",
      "14900 [D loss: 0.077119] [G loss: -19.075186]\n",
      "15000 [D loss: -0.845047] [G loss: -20.930613]\n",
      "15100 [D loss: -1.220576] [G loss: -23.470928]\n",
      "15200 [D loss: -0.596487] [G loss: -24.000011]\n",
      "15300 [D loss: -0.183274] [G loss: -25.271929]\n",
      "15400 [D loss: -0.807091] [G loss: -23.251953]\n",
      "15500 [D loss: 0.241693] [G loss: -24.304815]\n",
      "15600 [D loss: -0.367745] [G loss: -22.628479]\n",
      "15700 [D loss: -0.155124] [G loss: -21.705427]\n",
      "15800 [D loss: -0.128948] [G loss: -28.446728]\n",
      "15900 [D loss: -0.955227] [G loss: -25.401169]\n"
     ]
    }
   ],
   "source": [
    "train(epochs=30000, batch_size=32, sample_interval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-10T15:02:04.369Z"
    }
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (10, latent_dim))\n",
    "gen_imgs = generator.predict(noise)\n",
    "gen_imgs = 0.5 * gen_imgs + .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-10T15:02:04.373Z"
    }
   },
   "outputs": [],
   "source": [
    "gen_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-10T15:02:04.382Z"
    }
   },
   "outputs": [],
   "source": [
    "gen_imgs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-10T15:02:04.387Z"
    }
   },
   "outputs": [],
   "source": [
    "gen_imgs.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
