{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:13:48.658991Z",
     "start_time": "2018-07-12T21:13:48.655508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "from functools import partial\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:11:24.586073Z",
     "start_time": "2018-07-12T21:11:24.583007Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def ln_func(x):\n",
    "    return tf.contrib.layers.layer_norm(x)\n",
    "\n",
    "layer_norm = lambda : keras.layers.Lambda(ln_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:25:34.784073Z",
     "start_time": "2018-07-12T21:25:34.766649Z"
    }
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100\n",
    "\n",
    "# Following parameter and optimizer set as recommended in paper\n",
    "n_critic = 5\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=.5)\n",
    "lrelu = lambda x: keras.activations.relu(x, alpha=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:30.605683Z",
     "start_time": "2018-07-12T21:27:29.105066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 7840)              791840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 7840)              31360     \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 7, 7, 160)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 14, 14, 80)        204880    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 80)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 28, 28, 40)        51240     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 28, 28, 40)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 28, 28, 1)         641       \n",
      "=================================================================\n",
      "Total params: 1,080,441\n",
      "Trainable params: 1,064,521\n",
      "Non-trainable params: 15,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dim = 40\n",
    "k = 4\n",
    "\n",
    "# Build the generator and critic\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(dim*4 * 7 * 7, activation=\"relu\", input_dim=latent_dim),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Reshape((7, 7, dim*4)),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(dim*2, kernel_size=k, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2DTranspose(dim, kernel_size=k, padding=\"same\", strides=2, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    \n",
    "    keras.layers.Conv2DTranspose(channels, kernel_size=k, padding=\"same\", strides=1, activation=\"tanh\"),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "noise = keras.Input(shape=(latent_dim,))\n",
    "img = model(noise)\n",
    "\n",
    "generator = keras.Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:31.362272Z",
     "start_time": "2018-07-12T21:27:30.635532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 32)        544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 64)          32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 4, 4, 128)         131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 167,521\n",
      "Trainable params: 167,073\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dim = 32\n",
    "k = 4\n",
    "DROP = 0.40\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(dim, kernel_size=k, strides=2, input_shape=img_shape, padding=\"same\", activation=lrelu),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(dim*2, kernel_size=k, strides=2, padding=\"same\", activation=lrelu),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Conv2D(dim*4, kernel_size=k, strides=2, padding=\"same\", activation=lrelu),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(DROP),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "img = keras.Input(shape=img_shape)\n",
    "validity = model(img)\n",
    "\n",
    "critic =  keras.Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:31.794267Z",
     "start_time": "2018-07-12T21:27:31.791331Z"
    }
   },
   "outputs": [],
   "source": [
    "### Relativistic average Standard GAN\n",
    "\n",
    "# No sigmoid activation in last layer of generator because BCEWithLogitsLoss() already adds it\n",
    "\n",
    "# BCE_stable = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# # Discriminator loss\n",
    "# errD = ((BCE_stable(y_pred - torch.mean(y_pred_fake), y) + BCE_stable(y_pred_fake - torch.mean(y_pred), y2))/2\n",
    "# errD.backward()\n",
    "\n",
    "# # Generator loss (You may want to resample again from real and fake data)\n",
    "# errG = ((BCE_stable(y_pred - torch.mean(y_pred_fake), y2) + BCE_stable(y_pred_fake - torch.mean(y_pred), y))/2\n",
    "# errG.backward()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:32.443423Z",
     "start_time": "2018-07-12T21:27:32.440677Z"
    }
   },
   "outputs": [],
   "source": [
    "def noop_loss(target, output):\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:32.965204Z",
     "start_time": "2018-07-12T21:27:32.961260Z"
    }
   },
   "outputs": [],
   "source": [
    "def rasg_loss(inputs):\n",
    "    \n",
    "    \n",
    "    y_pred_target = inputs[0]\n",
    "    y_pred_off = inputs[1]\n",
    "    \n",
    "    zeros_bce = K.binary_crossentropy(y_pred_target - K.mean(y_pred_off), K.zeros_like(y_pred_target), from_logits=True)\n",
    "    ones_bce = K.binary_crossentropy(y_pred_off - K.mean(y_pred_target), K.ones_like(y_pred_target), from_logits=True)\n",
    "    \n",
    "    return zeros_bce + ones_bce\n",
    "\n",
    "def rasg_loss_layer():\n",
    "    \n",
    "    return keras.layers.Lambda(rasg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:34.668865Z",
     "start_time": "2018-07-12T21:27:33.669934Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#       for the Critic\n",
    "#-------------------------------\n",
    "\n",
    "# Freeze generator's layers while training critic\n",
    "critic.trainable = True\n",
    "generator.trainable = False\n",
    "\n",
    "# Image input (real sample)\n",
    "real_img = keras.Input(shape=img_shape)\n",
    "\n",
    "# Noise input\n",
    "z_disc = keras.Input(shape=(latent_dim,))\n",
    "# Generate image based of noise (fake sample)\n",
    "fake_img = generator(z_disc)\n",
    "\n",
    "# Discriminator determines validity of the real and fake images\n",
    "y_pred_fake = critic(fake_img)\n",
    "y_pred = critic(real_img)\n",
    "\n",
    "critic_loss = rasg_loss_layer()([y_pred, y_pred_fake])\n",
    "\n",
    "critic_model = keras.Model(inputs=[real_img, z_disc],\n",
    "                    outputs=[critic_loss])\n",
    "critic_model.compile(loss=[noop_loss],\n",
    "                                optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:34.934097Z",
     "start_time": "2018-07-12T21:27:34.875925Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------\n",
    "# Construct Computational Graph\n",
    "#         for Generator\n",
    "#-------------------------------\n",
    "\n",
    "# For the generator we freeze the critic's layers\n",
    "critic.trainable = False\n",
    "generator.trainable = True\n",
    "\n",
    "\n",
    "gen_loss = rasg_loss_layer()([y_pred_fake, y_pred])\n",
    "\n",
    "gen_model = keras.Model(inputs=[real_img, z_disc],\n",
    "                    outputs=[gen_loss])\n",
    "gen_model.compile(loss=[noop_loss],\n",
    "                                optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:27:35.673339Z",
     "start_time": "2018-07-12T21:27:35.662942Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "\n",
    "n_critic = 1\n",
    "\n",
    "def train(steps, batch_size, sample_interval=50):\n",
    "\n",
    "    shutil.rmtree(\"images\", ignore_errors=True)\n",
    "    os.makedirs(f\"images\", exist_ok=True)\n",
    "    \n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = -np.ones((batch_size, 1))\n",
    "    fake =  np.ones((batch_size, 1))\n",
    "    dummy = np.zeros((batch_size, 1)) # Dummy gt for gradient penalty\n",
    "    for step in tqdm(range(1, steps+1)):\n",
    "\n",
    "        # sample for Critic\n",
    "        \n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        # Sample generator input\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        # Train the critic\n",
    "        d_loss = critic_model.train_on_batch([imgs, noise],\n",
    "                                                        valid)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "        \n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        # Sample generator input\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gen_model.train_on_batch([imgs, noise], valid)\n",
    "        \n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if step % sample_interval == 0:\n",
    "            print_string = f\"step: {step}, D: {d_loss:g}, G: {g_loss:g}\"\n",
    "            print(print_string)\n",
    "            sample_images(print_string, step)\n",
    "\n",
    "def sample_images(print_string, step):\n",
    "    # make a video with \n",
    "    # >ffmpeg -framerate 4 -pattern_type glob -i mnist_*.png -pix_fmt yuv420p output.mp4\n",
    "    \n",
    "    \n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 1\n",
    "\n",
    "    fig, axs = plt.subplots(r, c, sharex=True, sharey=True, frameon=False, figsize=(5,5))\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray', aspect=\"auto\")\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.tight_layout(h_pad=0, w_pad=0)\n",
    "    plt.suptitle(print_string, backgroundcolor=\"white\", fontsize=7)\n",
    "    fig.savefig(f\"images/mnist_{step:05d}.png\", dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T21:36:08.524895Z",
     "start_time": "2018-07-12T21:27:36.384659Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5551e8455a3f479e9a58591533a39708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 50, D: -22.9684, G: 76.11\n",
      "step: 100, D: -647.664, G: 521.969\n",
      "step: 150, D: -167.107, G: 323.056\n",
      "step: 200, D: -272.203, G: 167.697\n",
      "step: 250, D: -227.347, G: 130.947\n",
      "step: 300, D: -105.172, G: 7.00066\n",
      "step: 350, D: -221.548, G: 287.815\n",
      "step: 400, D: -200.115, G: 51.8454\n",
      "step: 450, D: -131.229, G: 131.447\n",
      "step: 500, D: -151.489, G: 309.293\n",
      "step: 550, D: -243.493, G: 262.96\n",
      "step: 600, D: -202.014, G: 80.7457\n",
      "step: 650, D: -364.984, G: 144.29\n",
      "step: 700, D: -256.516, G: 337.985\n",
      "step: 750, D: -300.863, G: 214.156\n",
      "step: 800, D: -90.0517, G: 150.062\n",
      "step: 850, D: -279.312, G: 254.462\n",
      "step: 900, D: 162.799, G: 185.565\n",
      "step: 950, D: -218.679, G: 501.021\n",
      "step: 1000, D: -427.274, G: 560.599\n",
      "step: 1050, D: -134.299, G: 269.479\n",
      "step: 1100, D: -283.378, G: 238.182\n",
      "step: 1150, D: -543.579, G: -35.8385\n",
      "step: 1200, D: -258.428, G: 729.255\n",
      "step: 1250, D: -497.878, G: 394.878\n",
      "step: 1300, D: -330.567, G: 608.073\n",
      "step: 1350, D: -408.889, G: 406.245\n",
      "step: 1400, D: -17.0443, G: 465.391\n",
      "step: 1450, D: 70.7688, G: 374.246\n",
      "step: 1500, D: -656.877, G: 421.493\n",
      "step: 1550, D: -499.69, G: -176.129\n",
      "step: 1600, D: -552.264, G: 488.34\n",
      "step: 1650, D: -382.818, G: 524.284\n",
      "step: 1700, D: -378.843, G: 466.322\n",
      "step: 1750, D: -302.024, G: 472.449\n",
      "step: 1800, D: -460.367, G: 234.914\n",
      "step: 1850, D: -348.464, G: 263.477\n",
      "step: 1900, D: -791.405, G: -124.687\n",
      "step: 1950, D: -24.7462, G: 179.063\n",
      "step: 2000, D: -126.374, G: 709.378\n",
      "step: 2050, D: -675.198, G: 168.548\n",
      "step: 2100, D: -241.887, G: 15.6053\n",
      "step: 2150, D: -719.632, G: 977.155\n",
      "step: 2200, D: -508.527, G: 1129.73\n",
      "step: 2250, D: -804.746, G: 606.132\n",
      "step: 2300, D: -745.547, G: 780.763\n",
      "step: 2350, D: -1149.51, G: 1053.87\n",
      "step: 2400, D: -961.558, G: 212.789\n",
      "step: 2450, D: -1592.42, G: 912.497\n",
      "step: 2500, D: -169.114, G: 129.438\n",
      "step: 2550, D: -798.466, G: 1167.72\n",
      "step: 2600, D: -795.079, G: 769.944\n",
      "step: 2650, D: -437.496, G: 1791.25\n",
      "step: 2700, D: -1001.44, G: 1071.66\n",
      "step: 2750, D: -557.912, G: 310.419\n",
      "step: 2800, D: -851.406, G: 921.946\n",
      "step: 2850, D: -1139.3, G: -593.557\n",
      "step: 2900, D: -146.5, G: 759.445\n",
      "step: 2950, D: -776.21, G: -803.023\n",
      "step: 3000, D: -1819.28, G: -181.116\n",
      "step: 3050, D: -677.295, G: 1596.76\n",
      "step: 3100, D: -360.128, G: 1746.01\n",
      "step: 3150, D: -1329.55, G: 793.925\n",
      "step: 3200, D: -1799.69, G: 1198.42\n",
      "step: 3250, D: -1498.33, G: 922.066\n",
      "step: 3300, D: -1913.9, G: 838.633\n",
      "step: 3350, D: 16.7239, G: 1064.27\n",
      "step: 3400, D: -330.42, G: -270.845\n",
      "step: 3450, D: -649.377, G: 172.816\n",
      "step: 3500, D: -552.078, G: 873.83\n",
      "step: 3550, D: -348.225, G: 1205.1\n",
      "step: 3600, D: -804.971, G: 1401.55\n",
      "step: 3650, D: -2435.86, G: 1222.49\n",
      "step: 3700, D: -1520.65, G: 772.945\n",
      "step: 3750, D: -937.989, G: 1704.16\n",
      "step: 3800, D: -790.689, G: -132.504\n",
      "step: 3850, D: 105.016, G: 646.465\n",
      "step: 3900, D: -2164.53, G: 883.106\n",
      "step: 3950, D: -1163.46, G: 175.963\n",
      "step: 4000, D: -2323.63, G: 1412.58\n",
      "step: 4050, D: -1781.35, G: 949.193\n",
      "step: 4100, D: -2510.7, G: 1106.73\n",
      "step: 4150, D: -833.643, G: 2057.58\n",
      "step: 4200, D: -581.917, G: 2499.42\n",
      "step: 4250, D: -2414.11, G: 1626.8\n",
      "step: 4300, D: -2845.01, G: 538.825\n",
      "step: 4350, D: -200.929, G: 2787.92\n",
      "step: 4400, D: -2102.11, G: 1352.1\n",
      "step: 4450, D: -406.686, G: 1422.82\n",
      "step: 4500, D: -1676.76, G: 2200.61\n",
      "step: 4550, D: -199.574, G: 1847.95\n",
      "step: 4600, D: 439.718, G: 941.329\n",
      "step: 4650, D: -2314.13, G: 1089.52\n",
      "step: 4700, D: -614.043, G: 482.089\n",
      "step: 4750, D: -2169.68, G: 3160.87\n",
      "step: 4800, D: -1553.84, G: 2306.54\n",
      "step: 4850, D: -441.679, G: 945.337\n",
      "step: 4900, D: -1803.57, G: 1193.98\n",
      "step: 4950, D: -3152.25, G: 426.022\n",
      "step: 5000, D: -2512.61, G: 2025.03\n",
      "step: 5050, D: -1201.74, G: 743.025\n",
      "step: 5100, D: -1109.34, G: 2756.67\n",
      "step: 5150, D: -1322.15, G: 257.422\n",
      "step: 5200, D: -1688.53, G: 1408.06\n",
      "step: 5250, D: 309.522, G: -257.283\n",
      "step: 5300, D: -1645.2, G: 398.835\n",
      "step: 5350, D: -2415.28, G: 2932.57\n",
      "step: 5400, D: 121.221, G: 2331.85\n",
      "step: 5450, D: -2368.01, G: 1090.86\n",
      "step: 5500, D: -1243.99, G: 2544.87\n",
      "step: 5550, D: -4086.59, G: 1230.9\n",
      "step: 5600, D: -548.149, G: 1302.48\n",
      "step: 5650, D: 1210.69, G: 606.061\n",
      "step: 5700, D: -1975.37, G: 2519.07\n",
      "step: 5750, D: -1582.56, G: 2484.22\n",
      "step: 5800, D: 1891.78, G: 915.514\n",
      "step: 5850, D: 32.4052, G: 2876.55\n",
      "step: 5900, D: -2356.46, G: 1654.39\n",
      "step: 5950, D: -1265.9, G: 2075.26\n",
      "step: 6000, D: -2275.52, G: 2447.27\n",
      "step: 6050, D: -2377.86, G: 160.951\n",
      "step: 6100, D: -2808.29, G: 2615.38\n",
      "step: 6150, D: -1193.92, G: 3801.89\n",
      "step: 6200, D: 186.028, G: 2011.38\n",
      "step: 6250, D: -600.791, G: -79.7033\n",
      "step: 6300, D: -1145.43, G: 1306.98\n",
      "step: 6350, D: -701.412, G: 3693.67\n",
      "step: 6400, D: 1450.42, G: 2491.76\n",
      "step: 6450, D: -3345.13, G: 406.352\n",
      "step: 6500, D: 1316.02, G: 115.583\n",
      "step: 6550, D: -3919.32, G: 6205.17\n",
      "step: 6600, D: -2804.82, G: 6834.59\n",
      "step: 6650, D: -1168.52, G: 1888.03\n",
      "step: 6700, D: -648.69, G: 1999.74\n",
      "step: 6750, D: 244.23, G: 558.288\n",
      "step: 6800, D: -2743.84, G: -625.325\n",
      "step: 6850, D: -1205.71, G: 1504.16\n",
      "step: 6900, D: -2761.43, G: 1341.99\n",
      "step: 6950, D: -1730.01, G: -83.8178\n",
      "step: 7000, D: -6059.84, G: -633.967\n",
      "step: 7050, D: -3373.42, G: 924.924\n",
      "step: 7100, D: 19.5038, G: 3647.51\n",
      "step: 7150, D: -1667.98, G: 4504.66\n",
      "step: 7200, D: -5190.06, G: -15.287\n",
      "step: 7250, D: -1767.64, G: 1936.05\n",
      "step: 7300, D: -2556.98, G: 329.675\n",
      "step: 7350, D: -5891.34, G: 362.066\n",
      "step: 7400, D: -5143.51, G: 1214.73\n",
      "step: 7450, D: -4773.25, G: 4315.28\n",
      "step: 7500, D: -2317.93, G: 848.781\n",
      "step: 7550, D: -1067.06, G: -1362.36\n",
      "step: 7600, D: -2433.23, G: 3086.43\n",
      "step: 7650, D: -2881.53, G: 273.757\n",
      "step: 7700, D: -1177.03, G: 2227.1\n",
      "step: 7750, D: -3084.74, G: 1777.98\n",
      "step: 7800, D: -5526.86, G: 1770.07\n",
      "step: 7850, D: -5508.57, G: 2943.17\n",
      "step: 7900, D: -1026.83, G: 1263.19\n",
      "step: 7950, D: -4409.98, G: 2596.18\n",
      "step: 8000, D: -1915.19, G: 4363.13\n",
      "step: 8050, D: -4895.48, G: 6747.37\n",
      "step: 8100, D: -2828.09, G: 4628.15\n",
      "step: 8150, D: -799.659, G: 3868.16\n",
      "step: 8200, D: -1269.63, G: 1701.09\n",
      "step: 8250, D: -1837.68, G: 7117.52\n",
      "step: 8300, D: -2556.57, G: 2126.5\n",
      "step: 8350, D: -2273.83, G: 8096.65\n",
      "step: 8400, D: -6634.15, G: 3933.27\n",
      "step: 8450, D: -3433.6, G: 3830.73\n",
      "step: 8500, D: 10.8452, G: 4330.16\n",
      "step: 8550, D: -2407.08, G: -998.967\n",
      "step: 8600, D: -21.9414, G: 3003.39\n",
      "step: 8650, D: 260.496, G: 1874.84\n",
      "step: 8700, D: -6755.94, G: 1536.27\n",
      "step: 8750, D: -3089.07, G: 4653.17\n",
      "step: 8800, D: -4312.46, G: 4492.66\n",
      "step: 8850, D: -5568.78, G: 1205.53\n",
      "step: 8900, D: -6756.09, G: 4526.11\n",
      "step: 8950, D: -1468.52, G: 4583.04\n",
      "step: 9000, D: -1803.58, G: 3390.73\n",
      "step: 9050, D: -4764.62, G: 1163.42\n",
      "step: 9100, D: 647.182, G: 51.0356\n",
      "step: 9150, D: -1938.67, G: 3148.21\n",
      "step: 9200, D: -4267.41, G: 5418.27\n",
      "step: 9250, D: -3066.57, G: 4950.46\n",
      "step: 9300, D: 402.455, G: 4778.55\n",
      "step: 9350, D: -2716.39, G: 1685.67\n",
      "step: 9400, D: -4194.36, G: 4483.58\n",
      "step: 9450, D: -699.666, G: 3781.57\n",
      "step: 9500, D: 1233.04, G: -230.399\n",
      "step: 9550, D: -4067.83, G: 5971.29\n",
      "step: 9600, D: -3751.57, G: -2126.91\n",
      "step: 9650, D: -4168.27, G: 6853.33\n",
      "step: 9700, D: -7762.62, G: 5383.29\n",
      "step: 9750, D: -5663.88, G: 3485.18\n",
      "step: 9800, D: -4737.76, G: 2843.98\n",
      "step: 9850, D: -2473.93, G: 3769.99\n",
      "step: 9900, D: -3432.79, G: 6280.97\n",
      "step: 9950, D: -8099.64, G: 5211.59\n",
      "step: 10000, D: -3701.34, G: 886.915\n"
     ]
    }
   ],
   "source": [
    "train(steps=10000, batch_size=32, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
